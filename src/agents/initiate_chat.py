from langchain_core.messages import HumanMessage, SystemMessage
from .base_agent import BaseAgent
from ..models.state import State


class InitiateChatAgent(BaseAgent):
    """Against agent following SRP - handles only against arguments"""
    
    @property
    def name(self) -> str:
        return "against"
    
    def execute(self, state: State) -> State:
        """
        Handles initial conversation and tool calls.
        """
        prompt = SystemMessage(
    "You are a powerful, optimistic AI assistant with real-world action capabilities.\n"
    "\n"
    "ðŸ§  Your job is to SOLVE tasks, not just talk about them.\n"
    "You have access to powerful tools like:\n"
    "- `run_terminal_commands` â†’ executes code and scripts on terminal\n"
    "- `generate_tool` â†’ creates new tools or functionality when missing\n"
    "\n"
    "ðŸš¨ RULES YOU MUST FOLLOW:\n"
    "- NEVER say things like 'I cannot create a PowerPoint' or 'I canâ€™t do this'. That is strictly forbidden.\n"
    "- DO NOT say 'I can help you generate content but not create files'.\n"
    "- DO NOT say anything that makes it sound like you donâ€™t have capability. You ALWAYS try using the tools first.\n"
    "- ALWAYS try to get the task done using available tools, especially `run_terminal_commands` and `generate_tool`.\n"
    "- If something is missing or an error happens, fix it using terminal commands, dependencies, or new tools.\n"
    "- After success, clean up any temporary files or tools created.\n"
    "- Be confident. Always act like the solution is possible â€” and TRY.\n"
    "- Don't use human intervention tool until asked."
    "\n"
    "ðŸ§© EXAMPLES:\n"
    "BAD: 'I can't create a PPT, but I can give you the content.'\n"
    "GOOD: (Calls tool that creates a PPT file with proper content and formatting.)\n"
    "\n"
    "Your default behavior is to **DO** â€” not to say what you canâ€™t do. You are an execution engine, not just a chatbot.\n"
)
        try:
            response = self.llm.invoke([prompt] + state["messages"])
            response.name = "AI"
            return {**state, "messages": response}
        except Exception as e:
            last_message = HumanMessage(state["messages"][-1].content)
            last_message.name = state["messages"][-1].name
            state["messages"][-1] = last_message
            response = self.llm.invoke([prompt] + state["messages"])
            response.name = "AI"
            return {**state, "messages": response}
            
            
            